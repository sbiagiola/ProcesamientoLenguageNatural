# ğŸ“˜ Procesamiento de Lenguaje Natural

## ğŸ“Œ DescripciÃ³n

Este repositorio contiene implementaciones y experimentos relacionados con **Procesamiento de Lenguaje Natural (NLP)**, desarrollados en el marco de trabajos prÃ¡cticos acadÃ©micos y exploraciÃ³n personal en el Ã¡rea de **Inteligencia Artificial**.

El proyecto estÃ¡ abordado desde una **perspectiva de ingenierÃ­a**, priorizando la claridad conceptual, la correcta implementaciÃ³n de modelos y la evaluaciÃ³n rigurosa de resultados, utilizando Python y PyTorch.

---

## ğŸ¯ Objetivos

- Aplicar tÃ©cnicas fundamentales de NLP como limpieza de texto, tokenizaciÃ³n y vectorizaciÃ³n.
- Entrenar y evaluar modelos supervisados para tareas de clasificaciÃ³n de texto.
- Explorar enfoques basados en *deep learning* para el procesamiento del lenguaje.
- Documentar experimentos de forma clara y reproducible para uso acadÃ©mico y profesional.

---

## ğŸ—‚ Estructura del Repositorio

```
ProcesamientoLenguageNatural/
â”œâ”€â”€ README.md
â”œâ”€â”€ README.es.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ torch_helpers.py
â”œâ”€â”€ spa-eng/
â”‚   â””â”€â”€ spa.txt
â”œâ”€â”€ TP1/
â”‚   â””â”€â”€ Desafio_1.ipynb
â”œâ”€â”€ TP2/
â”‚   â”œâ”€â”€ tp2.ipynb
â”‚   â””â”€â”€ songs_dataset/
â”œâ”€â”€ TP3/
â”‚   â””â”€â”€ TP3.ipynb
â””â”€â”€ TP4/
    â”œâ”€â”€ Tp4.ipynb
    â”œâ”€â”€ tp4.py
    â””â”€â”€ graphics/
```

### Contenido

- **TP1/** - IntroducciÃ³n a word embeddings y vectorizaciÃ³n
- **TP2/** - Modelos de lenguaje y generaciÃ³n de texto
- **TP3/** - Arquitecturas recurrentes (RNN/LSTM) para clasificaciÃ³n
- **TP4/** - Seq2Seq con atenciÃ³n y Transformers para traducciÃ³n automÃ¡tica
- **torch_helpers.py** - Utilidades para tokenizaciÃ³n, padding y entrenamiento
- **spa-eng/** - Dataset Tatoeba de traducciÃ³n espaÃ±ol-inglÃ©s

---

## âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos

- Python 3.8 o superior  
- Jupyter Notebook  
- PyTorch  
- NumPy, Pandas  

### Clonar el repositorio

```bash
git clone https://github.com/sbiagiola/ProcesamientoLenguageNatural.git
cd ProcesamientoLenguageNatural
```

### (Opcional) Crear un entorno virtual

```bash
python3 -m venv .venv
source .venv/bin/activate    # Linux / macOS
.venv\Scripts\activate       # Windows
```

### Instalar dependencias

```bash
pip install -r requirements.txt
```

## â–¶ï¸ Uso

### Iniciar Jupyter Notebook

```bash
jupyter notebook
```

### Ejecutar trabajos prÃ¡cticos

1. Navegar a la carpeta del TP deseado (TP1/, TP2/, TP3/, TP4/)
2. Abrir el notebook correspondiente
3. Ejecutar las celdas en orden

### Estructura de cada notebook

Cada trabajo prÃ¡ctico incluye:

- **IntroducciÃ³n**: Contexto y objetivos del ejercicio
- **PreparaciÃ³n de datos**: Carga, limpieza y tokenizaciÃ³n
- **ImplementaciÃ³n**: DefiniciÃ³n de arquitecturas y modelos
- **Entrenamiento**: ConfiguraciÃ³n de hiperparÃ¡metros y optimizaciÃ³n
- **EvaluaciÃ³n**: MÃ©tricas de rendimiento y anÃ¡lisis de resultados
- **Conclusiones**: InterpretaciÃ³n y lecciones aprendidas

## ğŸ§ª Temas Abordados

### TP1 - Word Embeddings
- VectorizaciÃ³n de texto (Bag of Words, TF-IDF)
- Word2Vec y embeddings pre-entrenados
- AnÃ¡lisis de similitud semÃ¡ntica

### TP2 - Modelos de Lenguaje
- N-gramas y predicciÃ³n de palabras
- GeneraciÃ³n de texto
- ClasificaciÃ³n de textos por autor

### TP3 - Redes Recurrentes
- Arquitecturas RNN y LSTM
- ClasificaciÃ³n de secuencias
- Manejo de secuencias de longitud variable

### TP4 - Seq2Seq y Transformers
- TraducciÃ³n automÃ¡tica inglÃ©s-espaÃ±ol
- LSTM bidireccional con atenciÃ³n Bahdanau
- Arquitectura Transformer
- ComparaciÃ³n de modelos y anÃ¡lisis de rendimiento

## ğŸ§° TecnologÃ­as Utilizadas

| TecnologÃ­a | VersiÃ³n | DescripciÃ³n |
|------------|---------|-------------|
| Python | 3.8+ | Lenguaje principal |
| PyTorch | 2.x | Framework de deep learning |
| Jupyter Notebook | - | Entorno de experimentaciÃ³n interactiva |
| NumPy | - | Operaciones numÃ©ricas y matriciales |
| Pandas | - | ManipulaciÃ³n y anÃ¡lisis de datos |
| Matplotlib / Seaborn | - | VisualizaciÃ³n de resultados |
| NLTK / spaCy | - | Herramientas de procesamiento de texto |

## ğŸ“« Contribuciones

Este es un repositorio acadÃ©mico, pero las contribuciones son bienvenidas:

1. **Fork** el repositorio
2. Crea una **rama** para tu feature (`git checkout -b feature/mejora`)
3. **Commit** tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/mejora`)
5. Abre un **Pull Request**

TambiÃ©n podÃ©s abrir un **issue** para reportar errores o sugerir mejoras.

---

## ğŸ“„ Licencia

Este proyecto se distribuye bajo licencia **MIT**, permitiendo su uso acadÃ©mico y comercial con la debida atribuciÃ³n.

---

## ğŸ‘¤ Autor

**SebastiÃ¡n Biagiola**  
Ingeniero ElectrÃ³nico â€” EspecializaciÃ³n en Inteligencia Artificial  
Universidad Nacional de CÃ³rdoba

ğŸ”— [GitHub](https://github.com/sbiagiola)

---

## ğŸŒŸ Agradecimientos

- CÃ¡tedra de Procesamiento de Lenguaje Natural - UNC
- Datasets: Tatoeba Project, Song Lyrics
- Pre-trained embeddings: GloVe (Stanford NLP)
